---
title: 🐈日志2022-08-13
date: 2022-08-13 11:57:11
tags: dailynote
rating: ⭐️
excerpt: 
---
## TODO
- [ ] 多喝水，避免久坐不动
- [ ] 阅读一篇文献

## Tracking

- 11:57 作者：猎户座
链接：https://www.zhihu.com/question/414549247/answer/1418693854
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

泻药，个人正好分布式/并行计算和机器学习都有涉猎，以下浅谈一下自己的看法。其实，倒退十年，分布式/并行计算和机器学习一直是各自为战，老死不相往来的那种。做并行计算的一般不会机器学习，做机器学习的也没考虑到并行处理。近年来由于机器学习模型训练的开销越来越大，不分布式处理很难完成，ML System就一直火了起来。目前有很多分布式机器学习框架，但按照通信拓扑结构大体可以分为一下几种：①基于迭代式MapReduce/AllReduce的通信拓扑。包括Spark MLlib，以及传统的消息通信接口(MPI)等。②基于参数服务器(parameter server)的通信拓扑。包括CMU的Paramater Server和Petuum，以及微软的Maultiverso等。③基于数据流的通信拓扑。目前影响力比较大的基于数据流的系统是来自谷歌的Tensorflow。事实上，国内的大厂一般都会开发各自的机器学习平台，阿里的PAI，腾讯的Angle，百度的BML等，这方面的底层开发已经非常完善了，如果想直接找到分布式机器学习系统的研发岗其实不太可能，最多就是进去修修补补。接下来缺口比较大的个人认为应该是分布式机器学习算法，和大规模优化方法这一块，软件层面上还有很大的创新余地，针对特定的算力平台包括CPU,GPU,TPU等对机器学习算法做出并行优化，这方面的人才是非常紧缺了。像我所了解的HPC领域，虽然有足够的算力但没有与机器学习进行结合，而很多机器学习算法工程师对并行计算这块也不太了解，随着云计算和高性能计算的融合，我觉得机器学习算法加速这块需求量会很大。


## ReadList 
<!--此处显示今日已阅读文献-->
```dataview
TABLE file.tags AS 标签, rating AS 评分, comment AS 初步印象
FROM "02-Reading/mdnotes"
WHERE file.name[0] = "@"
WHERE file.tags[0] != "#unread"
WHERE file.mtime>=date(2022-08-13) AND file.mtime<date(2022-08-14)
SORT file.mtime desc
```

## DraftList
<!--此处显示今日新增或修改的草稿或其它非文献笔记文件-->

```dataview
TABLE file.tags AS Tags, status AS Status, destination AS Destination
FROM "01-Diary/本周事务" OR "03-Projects" OR "05-Life" OR "06-Cards"
WHERE (file.mtime>=date(2022-08-13) AND file.mtime<date(2022-08-14)) OR (file.ctime>=date(2022-08-13) AND file.ctime<date(2022-08-14))
SORT file.mtime desc
```