基本背景参数过多，训练慢，甚至无法训练。可以使用并行计算让计算更快（wall-clock time）

并行计算并不能减少总的 CPU 时间。

![[Pasted image 20220814223041.png]]
上图是一个典型的数据并行求解梯度

> 复杂的地方是**通信**

## 通信 

### 两种方法

+ share memory
+ Message passing

![[Pasted image 20220814223300.png]]

![[Pasted image 20220814223331.png]]

如果有多个节点，必须用 *Message Passing*

如何协调节点呢？用
+ **Client-Server Architecture**

![[Pasted image 20220814223441.png]]

+ Peer-to-Peer Architecture 

![[Pasted image 20220814223510.png]]

邻居之间可以通信

## MapReduce （同步）

![[Pasted image 20220814224821.png]]

![[Pasted image 20220814224901.png]]

计算主要是 worker 来做。

server 把参数广播到各个 worker 中。

![[Pasted image 20220814225010.png]]

![[Pasted image 20220814225232.png#center|基于MapReduce 的并行梯度下降法]]

![[Pasted image 20220814225411.png]]
通信和同步的时间会影响加速比。
![[Pasted image 20220814225535.png#center|speedup ratio]]

### Communication Cost

主要有两方面
+ Communication complexity：传输信息的多少
	+ 一般正比于模型参数数量
	+ 节点越多复杂度也越大
+ Communication latency：传输速度
	+ 取决于带宽

$$
Communication \text{ } time = \frac{complexity }{bandwith}+latency  
$$
### Synchronization Cost 

+ Bulk Synchronous(批量同步)

![[Pasted image 20220814230239.png]]

**所有 worker 都必须等最慢的 worker**.

问：如果一个节点挂了然后重启会怎样？
+ 这个节点会非常慢
+ 它叫 **Straggler**
+ Straggler effect
	+ wall-clock time 取决于最慢的结点
	+ 这是同步导致的

>这种模式要求每个 worker 都能够处理完整的模型，这对于模型规模很大的问题不太实用。

## 参数服务器实现异步梯度下降

由[[@Li2014]]提出
+ 特点：client-server architecture，messing-passing 通信，**异步**
+ Ray，开源系统，支持参数服务器

![[Pasted image 20220814231533.png]]

> 同步算法
> ![[Pasted image 20220814232640.png]]

![[Pasted image 20220814232706.png#center|异步算法]]
![[Pasted image 20220815005036.png]]
> 注意，这里的 $g_i$，是任意一个 worker。
> 这个发现来自[HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](https://arxiv.org/abs/1106.5730)
> 这样操作能加快算法，并且收敛效果好。


![[Pasted image 20220815005227.png]]
可以看到 worker3 在 $t_1$ 时的梯度是过时的，会使参数变差。

因此，**worker 要求比较稳定**。

## Decentralized Network 实现

+ 特点：peer-to-peer 架构，只能邻接节点通信。

![[Pasted image 20220815005432.png]]

![[Pasted image 20220815005453.png]]

**理论分析**
+ 可以收敛并且效果很好
+ 收敛率与连接情况有关
	+ 如果节点构成完全图，会很快收敛
	+ 如果图不是强链接的，不收敛
![[Pasted image 20220815010200.png]]

## 总结

+ Why parallel computing in ML？减少 wall-clock time
+ How? 使用 multi-processors or mulit-nodes

### 重要的概念

+ Communication : sharing mem VS message passing
+ Architecture : client-server VS peer-to-peer
+ Synchronization : bulk sync VS async
+ Parallelism : 数据并行<font color=#777777>（最流行）</font> VS 模型并行 

### 并行计算编程模型

+ MapReduce : sync
+ Parameter Server : async
+ Decentralized : peer-to-peer，sync and async

### 并行计算 VS 分布式计算

> 目前基本是混用

![[Pasted image 20220815010700.png]]

****
![[Pasted image 20220815115503.png]]
+ reduce 之后，worker 并不知道计算的结果。
+ all-reduce 之后，worker 知道计算的结果。有两种实现方式
	+ reduce+broadcast
	+ all-to-all communication![[Pasted image 20220815115811.png]]
	每个节点把自己的结果交给其他节点。
		+ 效率太低，通信量太大
	+ ring all-reduce 

### ring all-reduce 

![[ezgif.com-gif-maker.gif]]
![[Pasted image 20220815132204.png]]

**缺陷：** 
1. 大部分的通道都在 idle 状态
2. Communication time: $\frac{md}{b}$
	1. m：number of GPUs
	2. d: number of parameters
	3. b: network bandwith 

**更高效的算法**
![[ezgif.com-gif-maker (1).gif]]

![[Pasted image 20220815133122.png]]

> ![[Pasted image 20220815120030.png]]

