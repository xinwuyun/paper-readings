---
alias: heFasterMoEModelingOptimizing2022
tags: MoE 语言模型 专家并行 分布式机器学习
rating: ⭐⭐⭐ 
share: false
ptype: article
---

# FasterMoE: modeling and optimizing training of large-scale dynamic pre-trained models
<cite>* Authors: [[Jiaao He]], [[Jidong Zhai]], [[Tiago Antunes]], [[Haojie Wang]], [[Fuwen Luo]], [[Shangfeng Shi]], [[Qin Li]]</cite>

* DOI: [10.1145/3503221.3508418](https://doi.org/10.1145/3503221.3508418)

* [Local library](zotero://select/items/1_YHZJN3BJ)

***

### 初读印象

comment:: 专门用来并行化跑MoE的系统 

[FastMoE视频讲解](https://www.bilibili.com/video/BV1pt4y1V7mz?spm_id_from=333.337.search-card.all.click&vd_source=7def3d3fc89c6921c7aeadf5e4023d35&t=11718.8)
# 翻译

## 摘要

当前深度学习的趋势是将模型缩放到非常大的尺寸，目的是提高其准确性。混合专家模型(MoE)是目前最流行的预训练模型，它使训练万亿级以上参数的模型成为可能。由于专家的动态激活，即专门于某些领域的浅层，它允许对较大的模型进行稀疏训练，消除了模型大小和计算之间的线性关系。然而，与传统的深度学习模型不同的是，它给这些训练系统的效率带来了巨大的挑战，包括动态负载不平衡，低效的同步执行模式，阻塞的全对全通信。

为了解决这些挑战，我们首先提出了一个性能模型，该模型既能准确预测特定训练任务的不同操作的延迟，又能通过一种新型的屋顶线型模型直观地分析其端到端性能。然后，在此模型的指导下，我们发明了一种动态跟踪方法来处理负载不平衡，以及一种智能的细粒度调度，它将不同的操作分割并并发执行。我们设计了一种避免拥塞的专家选择策略，在允许修改专家选择的情况下，以较低的迭代延迟缓解网络拥塞。我们实现并集成上述优化作为一个通用系统，fastmoe，赋予高效的分布式MoE模型训练。fastmoe在不同的集群系统上进行评估，最多使用了 64 个GPU。与大型模型的最先进系统(包括ZeRO、GShard和基础层)相比，它实现了1.37 - 17.87的加速。

Source code of FasterMoE is now available at https://github.com/thu-pacman/FasterMoE.

## 1. Introduction

预训练模型是指已经用大量样本训练过的模型，其中包含知识。与从头训练一个新的模型相比，使用预先训练的模型可以大大减少资源消耗。因此，预训练模型在许多领域越来越受欢迎，如图像处理[22]，阅读理解[3]，语言生成[1,24,38]。近年来，学术界和工业界都对开发精度更高的预训练模型感兴趣。

提高模型精度的方法之一是增大模型的尺寸。研究表明，更大的模型带来更高的精度[1,5,11]。在这些作品中，mix -of- expert (MoE)[17]似乎有望将模型放大到极致尺寸。如图1所示，与直接将小模型缩放为大的密集模型不同，MoE模型由许多小模型组成，即专家模型。训练样本被输入不同的专家，由一个轻量级的可训练门网络动态选择。在MoE中，由于专家是稀疏激活的，节省了大量额外的计算量，与经典的密集预训练模型相比，它可以显著增加同一时间段内训练的样本数量，提高模型的精度。因此，这种动态模型对于训练一个巨型模型越来越重要，例如谷歌的GShard[11]和Facebook的BASE Layer[12]。

![[Pasted image 20220818153618.png#center|图1。用于训练大型模型的MoE结构。]]
虽然灵活的MoE结构使训练万亿规模以上的巨型模型更加可行，但成本仍然极高。GShard[11]中一个6000亿的MoE模型需要2048 个 tpu 4天来训练。为了减少训练时间，引入专家平行等位性对MoE模型进行分布式训练，将专家划分到不同的工人上，每个工人处理不同批次的训练样本(详见2.3节)。在MoE层中，每个输入都由系统通过网络发送给所需的专家。

现有的MoE培训方法效率低下的主要原因是动态的专家选择和灵活的MoE结构。我们总结了训练MoE模型时的三个主要挑战如下。
+ **动态专家选择**。随着模型尺寸的增加，专家通常分布在不同的worker中。一个受欢迎的专家比其他人收到更多的代币，这导致其常驻worker负载过重，而其他worker可能空闲。更糟糕的是，该模式在不同的迭代中动态变化。这种行为会显著影响硬件利用率和培训效率。
+ **低效率的同步操作**。所有专家都需要从许多其他worker那里获得他们的输入，这是训练MoE模型时最耗时的操作之一。它通常被实现为具有可变消息大小的同步all- to-all操作。考虑到不统一的专家选择会导致计算和通信的严重不平衡，这种启动同步操作的方法会导致更多的开销。
+ **模型设计与网络拓扑不匹配**。MoE模型训练中的专家选择对训练效率有显著影响，因为专家选择决定了负载均衡和通信流量。现有的工作，如GShard[11]和BASE Layer[12]使用不同的专家选择策略来平衡计算负载，而忽略了通信，尽管网络拓扑对通信性能至关重要。在当前广泛应用的网络拓扑结构中，网络竞争频繁发生，其原因是动图中复杂的通信。

为了解决这些挑战，我们提出了fastermoe，一个用于训练大型动态预训练模型的高效分布式系统。为了捕捉MoE引入的动态行为，我们建立了一个精确的训练任务绩效模型。给定一个MoE模型和系统配置，我们的性能模型可以首先估计操作的延迟，然后用一个类似屋顶线*（roofline-like）的模型将任务可视化，以便更好地理解其性能。在绩效模型的指导下，我们进一步提出了培训过程的三个关键优化策略。为了减少专家选择不平衡造成的空转，采用了动态跟踪技术。引入了一种细粒度的智能调度策略来异步执行计算和通信操作，充分利用了操作间的并行性。最后，设计了一种避免拥塞的专家选择策略，以降低迭代延迟，收敛效果良好。

FasterMoE 在2个不同的集群上进行测试，最多 64 个GPU。评估结果表明，与ZeRO Optimizer[25]相比，FasterMoE可实现高达17.87的加速，具有数学等价性。当允许修改专家选择时，FasterMoE在GShard上的收敛时间快1.37，在BASE Layer上的收敛时间快2.19。
总之，我们作出了以下贡献：
+ 我们设计了一个性能模型，该模型能够准确地估计给定的具有特定并行策略的MoE模型的性能。
+ 我们提出了一个类似屋顶线的模型来分析不同并行度的性能和理论极限，以及下面的优化改进。
+ 我们创建了一个智能的细粒度的通信和计算时间表，以共同减少它们的延迟。
+ 我们在运行时设计了一种调整后的专家选择策略，以获得更快的通信速度和更少的拥塞，而损失在有希望的斜率中减少。
+ 我们将上述技术实现到一个端到端MoE培训系统，fastermoe，并实现高达17.87加速比最先进的系统。
本文的其余部分组织如下。第2节介绍了分布式训练的背景和主要挑战。第3节介绍我们的性能模型，第4节介绍由我们的性能模型指导的优化策略。第5节评估fastermoe。更多相关的工作描述在第6节，和第7节总结本文。

## Background and Challenges

### 2.1 Transformer: 预训练模型的骨干

![[Pasted image 20220818172313.png#center|图2。Transformer block 的结构。]]

Transformer[34]是处理序列的最先进结构。例如文本[3]，蛋白质序列[29]，甚至图像[22]中的像素，使变形器作为许多预训练模型的基本结构。如图2所示，一个Transformer Block 由Attention层和多层感知机(MLP)两组成。

Attention 层通过在特定线性空间(Q和K)的每一对标记之间进行点积来提取序列标记之间的关系。两两乘积的结果矩阵称为注意矩阵。利用注意矩阵将不同权重token的嵌入向量相加，从V到F，提取它们之间的关系。注意层的结果被送入MLP层，该层通常由Transformer Block 中的两个巨大的全连接(FC)层组成。Transformer Block 中最耗时的计算是发生在MLP层的一般矩阵乘法(GeMM)。

### 2.2 MoE Structure

MoE[17]在现代大规模预训练模型中具有较强的能力。MoE的关键思想是它有许多小模型，即专家，组成一个大模型，直觉上不同的小模型是不同领域的专家，只有输入其领域的数据时才能被激活。

在 Transformer  中，MLP层通常用MoE扩展。在处理令牌时，只有少数最适合他们领域的专家被激活。回想一下，在非moe转换器模型中，MLP中有两个相邻的FC层。当模型规模扩大时，这些密集的层变得巨大，使得GeMM的计算量过大。在MoE模型中，GeMM的权重矩阵沿着一定的维数分割，使得每个部分仍然产生相同大小的输出，而GeMM的计算量仍然很小。换句话说，MoE允许在不增加计算量的情况下增加模型参数，这使得它成为目前生产万亿级以上预训练模型的最可行方法。

对于一个给定的输入，一个额外的模块，门，被引入来决定哪些专家应该被激活。gate通常是一个小的FC层，用于计算每个专家的匹配分数，并选择匹配分数最高的前 k 个专家。

### 2.3 Parallel Strategies

数据并行、模型并行和专家并行是分布式训练中常用的三种并行策略。

**数据并行**在所有worker上复制模型的参数。然后给每个工人不同批次的训练样本。工作人员全局同步渐变，并在每次迭代之后更新模型。虽然在每个迭代中没有通信，但是模型的大小不能超过单个工作人员的能力，这样就不可能扩展到大型模型。

**模型并行**按照一定的维度划分权重张量，即模型被划分为不同的分区并放置在不同的worker上。所有的worker一起处理全局批处理，并使用其相应的权重划分进行计算。在每一层之后，对嵌入向量进行聚合和再分布。但是，模型并行性受限于分区维度和层与层之间通信开销大的限制，无法高效地扩展到非常大的模型。

![[Pasted image 20220818200001.png#center|图3. 具有相关通信的专家并行度张量划分]]

专家并行(Expert parallelism)是针对MoE模型的一种特殊的并行方法，由GShard[11]首先提出。如图3所示，专家被放置在不同的工人上，每个工人使用不同批次的训练样本.对于非moe层，专家并行性与数据并行性表现相同。在MoE层中，序列中的令牌被发送给他们想要的专家所在的工人。与模型并行类似，每个MoE层的输出再次交换，重新组织成原始序列，用于下一层的计算。由于MoE模型通常有大量的专家，专家并行度比模型并行度更能随模型规模的增大而增大。

### 2.4 Challenges and Observations

当使用专家并行度训练 Transformer  时，一组挑战极大地影响了训练效率。在本节中，我们将描述此类挑战。

**倾斜的专家选择（Skewed expert selection）导致动载不平衡**。我们用一个例子来描述这个挑战。如图3所示，专家0收到3个token，比专家2多3个工作负载。结果，worker 2在下一次通信开始之前很长一段时间处于空闲状态，没有充分利用其可用的计算能力。考虑到训练数据自然遵循倾斜分布，一些专家比其他人更有可能被选中。

![[Pasted image 20220818201202.png#center|图4。训练不同的MoE模型时专家选择在某些迭代中的分布。]]

我们在训练两个由16位专家组成的真实模型时，收集每个token的专家选择，以观察不同专家的实际受欢迎程度。图4对训练期间的一些迭代进行了采样和可视化。在前500次迭代中观察到快速变化的不均匀分布。在图4a所示的MoE层中，专家的受欢迎程度在整个培训过程中都在不断变化。图4b展示了不同模型中的另一层，在这一层中，受欢迎程度更稳定，但仍然有很多不受欢迎的专家。事实上，放大图，可以看到许多小条纹，表明这些专家不受欢迎，尽管仍然忠实地处理其领域特定的数据。与此同时，16个专家中有4个处理约20%的token，平均为3.2。

更受欢迎的专家比不受欢迎的专家收到的 token 更多，这让他们手下的员工负担更重。这种动态行为没有充分利用现有的计算资源，影响了硬件的利用率，降低了模型的训练效率。因此，MoE培训系统面临的第一个挑战是如何处理倾斜专家选择造成的动态负载不平衡。

**同步执行模式的操作是低效的。** 专家并行中的 all-to-all 操作通常由通信库(如MPI[6]或NCCL[8])提供的同步操作符实现。考虑到不统一的专家选择会导致计算和通信的不平衡，这种同步执行方法会造成更高的资源浪费。当执行通信或计算时，其他硬件最终没有得到充分利用，而它们可以用于处理其他操作。然而，由于不同的通信和计算任务之间存在依赖关系，因此很难分割所有到所有的通信。如果数据传输的顺序设计不合理，很容易导致死锁。因此，第二个挑战是如何有效地组织通信和计算任务并行执行。

**专家并行导致严重的网络争用。** 最后，我们强调了专家签名与网络拓扑之间的不兼容性。在每次迭代中，多个通信操作同时执行，由于链路饱和的情况较少，会导致性能大幅下降。由于标记的专家分配规定了负载平衡和通信路径，执行标记的智能分配可以帮助降低训练的端到端延迟，而不影响模型的质量。因此，第三个挑战是如何设计一种网络拓扑感知令牌分配策略，以避免严重的网络争用。

## 3. 性能建模

为了评估和分析训练任务的性能，我们首先分别建立计算模型和通信模型。然后，我们引入一个类似屋顶线的模型来研究通信延迟和计算延迟是如何共同影响整体训练效率的。

![[Pasted image 20220818203935.png#center|符号表]]

### 3.1 Load-aware计算建模 

如前所述，GeMM是训练Transformer时的主要计算。现代大规模计算设备，如gpu，对常规计算进行了高度优化，如GeMM，实现了非常高的性能。根据我们的测量，在 Transformer 中运行典型模型尺寸和批量尺寸的GeMM时，NVIDIA Tesla V100 GPU可以达到其峰值吞吐量的90%以上。因此，我们用下面的公式来预测 Transformer Block 中MLP层的正向计算时延。

$$
L a t_{\text {comp }}=\max _{w \in \text { workers }}\left\{\frac{4 B_{w} \alpha H^{2}}{P_{w}}\right\}
$$
$B_{w}$ 表示worker w上的批大小，因为不同worker上模块的批大小在专家并行度上可能不同。H 是标记嵌入向量的长度，$\alpha H$是MLP中FC层之间的中间嵌入的长度。由于单个FMA操作占用2个操作，因此每次FC执行将占用2 $2 B_{w} \alpha H^{2}$ 2个操作。有2个fc，导致常数因子4。푃푤表示푤执行GeMM的平均吞吐量。端到端延迟是每个worker的最大延迟，因为所有worker在计算后都要交换特性。因此，该公式反映了计算中的负载不平衡。

一个潜在的问题是，对于那些$B_{w}$非常小的worker，它可能无法很好地利用其计算设备，从而导致不正确的延迟估计。然而，虽然没有达到峰值性能，但使用小$B_{w}$的计算延迟通常不会比使用大$B_{w}$的计算延迟大。由于巨大的$B_{w}$控制了整个计算延迟，这种预测的不准确性并不会使其有效性失效。

### 3.2 Topology-aware通信建模 

根据LogP模型[2]，通信的总体延迟由开销和延迟两部分组成。每个 token 的特征向量一般大于1024，说明传输数据的最小粒度大于4KB。因此，我们简化了模型，认为通信开销可以忽略不计。如果我们假设没有拥塞，互连的带宽就可以得到充分利用。假设在一个节点中通常有多个加速器，每个加速器都是一个worker，我们不仅应该考虑节点间的连接，还应该考虑节点内的连接，如PCIe、UPI和NVLink。

我们采用一种拓扑感知模型来预测集体通信操作的延迟。假设链接$l$在单个方向上的带宽为$W_{l}$，流量大小为$T_{l}$。通信的端到端延迟计算如下。

$$
L a t_{\mathrm{comm}}=\max _{l \in \operatorname{links}}\left\{\frac{T_{l}}{W_{l}}\right\}
$$

$W_l$ 可以由硬件规格和执行点对点带宽基准来确定。我们强调网络拓扑图是有向的。为了获得$T_l$，我们将每个链接建模为图中的一条边。用两个有向边表示双工链路，分别考虑两个方向的流量。因为在负载不平衡的情况下，链路的两个方向上的流量可能有很大的差异。链路的有效带宽不直接等于两个方向都忙时的有效带宽。

每条链路上的流量取决于算法和路由策略。在每个边缘上，对不同的操作采用不同的方法来计算流量。我们将在下面展示如何对3种常见通信进行建模。
+ **All-to-all-v** 用于将token从序列中的位置路由到它们所需的专家。由于专家选择的灵活性，每对工人之间的流量是高度可变的。由于专家选择的灵活性，每对工人之间的流量是高度可变的。我们假设all-to-all操作只是在所有工人对之间创建链接，并模拟地传输数据。根据拓扑类型的不同，采用一种算法来计算每个工作对之间的路径。对于每对工人，他们之间的流量在路径上的所有有向边上累积。
+ **All-reduce**算子广泛应用于数据同步中，包括数据并行度中重复模型参数的梯度，模型并行度中嵌入向量等。在每个worker上对一个大小为$s$的张量应用环all-reduce[30]，结果是每个worker在管道中总共发送$2\frac{n-1}{n}$给它的邻居。
+ **Broadcast and reduce**与all-reduce一样具有规律性，利用环形连接和流水线来降低其延迟。但与all-reduce不同的是，它们只通过每个链接发送总大小为$S$的消息。
> + ring All reduce 算法允许工作节点平均梯度并分散到所有节点，而不需要参数服务器。
> ![[Pasted image 20220818215117.png]]
> ![[Pasted image 20220818213314.png]]
> + All to All
> ![[Pasted image 20220818213408.png]]


### 3.3 DDL-Roofline Model

我们提出了一种分布式深度学习(DDL) Roofline模型来描述给定集群上特定训练任务的性能。计算和通信是并行MoE模型的两个关键因素。因此，我们定义**计算-通信的比率**$R_{CC}$，表示在DDL- Roofline的X轴上，如下所示。
$$
R_{C C}=\frac{L a t_{\mathrm{comp}}}{L a t_{\mathrm{comm}}}
$$
$L a t_{\mathrm{comp}}$和$L a t_{\mathrm{comm}}$分别表示由预测器估计的计算和通信延迟。$R_{CC}$表示任务是受计算限制还是受通信限制。当$R_{CC}$>1时，计算时间占用端到端延迟时间，否则通信占用大部分延迟时间。这个比率表明了应用不同优化的方向。

Y轴的变量为$\bar{P}$，表示所有worker的平均计算吞吐量。训练一个MoE MLP层时，计算如下。
$$
\bar{P}=\frac{12 \alpha H^{2} \sum_{w} B_{w}}{N L a t_{\mathrm{e} 2 \mathrm{e}}}
$$
$12 \alpha H^{2} \sum_{w} B_{w}$表示所有专家对所有令牌处理的总计算量，푁表示工人的数量。$Lat_{e2e}$是通过估计或测量迭代的端到端延迟。例如，在同步专家并行中，我们用$Lat_{e2e}$ =3$Lat_{comp}$ +4$Lat{comm}$来估计，因为向前和向后总共有3轮计算，4轮通信。$\hat{P}$直观地反映了所有worker设备的平均利用率，也可以直接指示一个系统的可扩展性.

![[Pasted image 20220818220804.png]]
图5。DDL-Roofline模型显示了不同的偏序和FasterMoE的优化 

理想情况下，通信和计算同时进行，我们得到了一个类似屋顶线的折线，如图5中实线所示的理论上限。计算公式如下。
$$
\bar{P}_{\text {ideal }}=P_{w} \min \left\{1, R_{C C}\right\}
$$
我们还用破折号突出了半理想曲线，它指的是在以同步方式进行训练时，硬件的充分利用。
$$
\begin{aligned}
\bar{P}_{\text {semi-ideal }} &=P_{w} \frac{L a t_{\mathrm{comp}}}{L a t_{\mathrm{comp}}+L a t_{\mathrm{comm}}} \\
&=P_{w} \frac{R_{C C}}{R_{C C}+1}
\end{aligned}
$$
在半理想情况下，端到端延迟是通信延迟和计算延迟的总和。最初的roofline模型[37]描述的是在单个设备上的程序，内存访问和计算自然是同时执行的，与此不同的是，分布式训练程序通常需要对系统进行显著的优化，以便同时执行它们。

**给定一个训练任务及其并行配置**，DDL- Roofline有助于更好地理解模型的训练吞吐量。下面，我们将展示几个示例，说明在训练特定的Transformer 模型时，并行策略是如何通过图5中的ddl - rooline反映出来的。

**数据并行**由理想折线左侧的两个点表示。由于同步MoE MLP层的梯度需要在$2NaH^2$个元素上执行all-reduce，这太昂贵了，导致$R_{CC}$很差。然而，由于全部约简可能与向后计算重叠，它可以稍微超出半理想曲线。
**模型并行**由于引入了较少的通信而具有较大的$R_{CC}$。它在B 个toekn的嵌入矩阵上执行2 all-reduce，总大小为2NBH。与数据并行相比，减少了$R_{CC}$>1的通信。但是当同步嵌入向量时，不能执行其他计算。这一特性迫使模型并行性同步执行，并阻止点移动到半理想曲线上方。
由于负载不平衡，**专家并行**在计算上比通信上引入了更多的延迟，因此它有很大的$R_{CC}$，但很差的$\hat{P}$，远低于半理想曲线。图5还展示了fastmoe中的优化。我们将在下面的DDL-Roofline中指出它们的特点。

## 4 Model-Guided优化方法 

### 4.1 轻量级动态跟踪策略

在MoE模型中，超过一半的输入token可以选择受欢迎的专家，导致严重的负载不平衡，如图4所示。尽管单个输入token的嵌入比模型参数小几个数量级，但来自所有其他worker的批量输入可能等于甚至大于模型参数。因此，需要权衡的是，传输如此多embedding向量的延迟是否可以用复制专家模型参数来替代。
![[Pasted image 20220818222904.png]]
图6。动态阴影的一个例子。不是将输入发送给worker1，而是复制expert1。

如图6所示，一些expert被复制到所有的worker上，即shadow expert，他们的参数，而不是他们的输入token，在网络上传输。它们的相关计算是在本地执行的，直观地减少了包含热门专家的工作人员的负载。

然而，动态跟踪具有挑战性，因为expert的popularity随着训练过程的变化而变化，每次迭代所做的决定可能不同。此外，参数不能像普通的分布式内存系统那样缓存，因为它们在每次迭代中都要更新，并且需要在更新过程中全局收集梯度。如果它们缓存在每个worker上，那么它们应该在每次迭代中进行更新，从而引入大量的额外开销。

为了解决这一挑战，我们利用性能模型来分析是否应该在运行时跟踪专家。我们预测训练迭代的端到端延迟，以检查性能增益，并据此采取行动。我们将在下面详细阐述我们的分析。

在原本不平衡的情况下，通信和计算由一组popular expert主导。通过计算其批大小$B_w$为$B_{w}=\sum_{i=1}^{N} T_{i w}$，其中$T_{iw}$个token从worker i发送到worker w，我们从总共N个工人中建模单个工人$w$的工作负载。

训练MLP层的一次迭代包含1个正向GeMM和2个反向GeMM，用于计算输入的梯度。all-to-all的通信有4轮，每轮2个向前和向后。在网络带宽固定的简化情况下，训练时延的计算如下。
$$
L a t_{\mathrm{imbl}}(B)=\max _{w}\left\{3 \frac{4 B_{w} \alpha H^{2}}{P}+4 \frac{B_{w} H}{W_{\text {net }}}\right\}
$$

为了shadow一个受欢迎的专家，我们必须首先将其参数传播给所有的工作者，然后使用获取的模型在本地token上运行计算。在后向阶段，每个工人分别计算其提取的专家的梯度，然后进行reduce操作。最后，参数更新操作在最受欢迎的专家最初所在的worker上执行。

在这种情况下，执行不平衡计算的开销被2个集合通信操作所取代，每个通信操作的大小为$2\alpha H^2$。由于多个受欢迎的专家被派往许多其他工作人员，负载不平衡的情况不太可能发生。shadowing$r$模型的延迟计算如下。
$$
L a t_{\text {shadow }}\left(r, B^{\prime}\right)=\max _{w}\left\{3 \frac{4 B_{w}^{\prime} \alpha H^{2}}{P}\right\}+2 r \frac{2 \alpha H^{2}}{W_{\text {net }}}
$$
出现以下任一情况时，shadowing策略更快
$$
B_{\max }>r \alpha H
$$
or
$$
\frac{3\left(B_{\max }-B_{\max }^{\prime}\right) \alpha H}{r \alpha H-B_{\max }}>\frac{P}{W_{\text {net }}}
$$
第一个条件表明传输输入的总开销高于传输模型。第二个条件表明减少的计算延迟大于增加的通信开销。在这两种情况下，都启用了动态shadow来减少端到端延迟。否则，通信开销太大，而且模型交换不能为减少延迟带来好处，因此不能执行。这种情况通常发生在不同工作人员的工作量平衡时。由图5中的箭头(1)表示，由于减少了空转，计算的延迟缩短了，导致了更低的$R_{CC}$和更高的$\hat{P}$.
我们在每个迭代的运行时选择专家进行跟踪。在每个worker上执行一个轻量级算法，如算法1所示。由于矩阵푇总是必须在所有工作人员之间可用，因此不引入额外的通信。根据上面的公式，它返回一组需要对其进行跟踪的专家。
![[Pasted image 20220818225936.png]]

### 4.2 异步细粒度智能调度

正如我们的DDL-Roofline所示，当通信和计算分开执行时，程序不能超出半理想曲线。此外，由于固有的大量沟通，增加$R_{CC}$是困难的。因此，我们提出了一种智能调度方法，将任务划分为更小的部分，并重新调度细粒度的通信和计算操作，以提高效率。细粒度调度允许计算和通信异步执行，从而更好地利用硬件，使其能够超越图5中箭头(2)所示的半理想曲线.

在专家并行中，通信遵循一种复杂的全对全模式。我们首先通过将工作人员划分为细粒度的组来分割所有人之间的通信。我们使用分组的两两交换算法[33]执行all-to-all。这些组形成一个大小为 n 的环，并以从0到$n-1$递增的步幅向其他组发送数据。对于组分配，我们遵循启发式方法，将紧密相连的工种置于同一组中，从而使同一组的工种之间的连接更快。组的大小由连接拓扑和相关的计算粒度共同确定。

![[Pasted image 20220818231016.png]]
从worker 0上看，在$S_{0,1}$中，worker 0在接收到group1的数据时，同时向group2发送数据。它的行为类似于$R_{0,1}$，$S_{0,2}$和$R_{0,2}$。由于空间的限制，它们没有绘制出来。
图7。细粒度操作切分。

在一个MoE层的前向或后向阶段，都涉及两个对称的全对全，并在它们之间进行计算。我们按照两两交换的方式分割计算，为重新组织它们留出空间。3n个操作由n个组中的所有worker分n个步骤执行。在步骤j中，组i中的worker执行以下3个操作，由图7中的示例实例化。

+ $S_{i,j}$：**sends** token 到组$t_{i, j}=(i-j)$并从$f_{i, j}=(i+j)$接收token(都对n取模)。
+ $C_{i,j}$：使用本地专家从$f_{i,j}$，在token上进行**计算**。
+ $R_{i,j}$：从$t_{i,j}$接收本地 token 的输出并把计算结果送回到$f_{i,j}$

因此，通信和计算都被分割成细粒度的任务，并以特定的顺序作为要求。图8a显示了一个按顺序执行操作的忠实调度。它的延迟与使用粗粒度操作符的原始同步执行模式相同。只要满足依赖关系，就可以乱序执行操作。

![[Pasted image 20220818232717.png]]
图8。在worker上的不同流上调度任务，最小化开销。

回想一下，**调度的目标是并行地执行这些操作**。为每个worker创建一个通信流和一个计算流，以执行不同类型的操作符。如图8b所示，在它的通信流中，它首先执行$S_{i, 0}, S_{i, 1}, \ldots, S_{i, n-1}$，然后从$R_{i,0}$到$R_{i,n-1}$。它的计算流从$C_{i,0}$执行到$C_{i,n-1}$。通过并行执行操作，端到端延迟显著降低。但是，所有操作都必须尊重它们的数据依赖关系，并在启动自己之前等待之前的任务执行。

我们用两流调度演示了最小化开销的方法。我们假设计算流在大多数时间是繁忙的。我们要强调的是，在相反的情况下，通信占用了大部分时间，根据DDL-Roofline，优化将几乎没有影响。由于计算流被完全占用，优化的主要机会是减少第一个S和最后一个R的延迟。图8c给出了一个例子。由于组2引入的开销比组3更低，因此将它放在调度的最后位置可以降低端到端延迟。注意，$S_{i,0}$从本地组接收令牌，这被认为是最快的操作，因为不涉及上层连接。$R_{i,n-1}$只与组i的邻居交换数据。从全局视图来看，步骤n-1中的所有组都被组织为一个环，并沿着环交换数据。这在除步骤0之外的所有步骤中充分利用了网络带宽。因此，最快的2个操作，即$S_{i,0}$和$R_{i,n-1}$，被放在智能调度的第一个和最后一个，最大限度地减少开销。

### 4.3 回避争用的专家选择策略

在MoE模型中，最终目标是用足够多的输入样本来训练所有的专家，而不是用他们最期望的专家来处理每个token。由于采用拟合分数作为权重对每个专家的输出进行汇总，改变专家的选择并不会带来数值上的错误。GShard[11]和BASE Layer[12]都改变了专家选择策略以实现特定目的。我们观察到专家选择策略可以与培训系统共同设计以提高效率。然而，模型的准确性会受到选择策略的影响。专家们可能被灌输了一些与其专业技能不太相关的代币，从而削弱了它的力量。因此，除了吞吐量，token和专家之间更好的拟合是值得赞赏的。

我们设计了一个拓扑感知的门，将输入以较低的延迟引导给专家。通过考虑特定硬件的网络拓扑结构，可以提高训练吞吐量。在树形结构的普通集群中，上层连接的带宽通常低于本地连接。与其他常规的集体交流不同，all-to-all 会导致这些联系上更高的contention。

假设交换机连接 N 个节点和每个节点上的M 个 workers。worker和主机之间的流量大致为$T_{w}=\frac{M N-1}{M N} B H$。同时，每个节点网口的流量为$T_{n}=\frac{M(N-1)}{N} B H$，大约比$T_w$大M倍。

为了减少拥塞，我们允许将最多 $L=\frac{W_{\text {net }}}{M W_{\text {local }}} B$ 个token定向到另一个节点。这里，$W_{net}$和$W_{local}$分别表示节点间和节点内的通信带宽。具体来说，如果有超过L个token，其最佳选择位于另一个节点上，则允许其中得分最高的L个token。它们的其余部分与其他token一起留在本地节点中重新选择它们所需的专家。整个网络的流量减少到$\frac{W_{\text {net }}}{W_{\text {local }}} B H$，所花费的时间与本地通信相同。这样就减少了上层链路拥塞的可能性，**降低了通信开销。通过减少通信开销**，可以在相同的时间内训练模型进行更多的迭代。此外，保留了最适合的专家和token配对，减少了其他选择空间有限的影响。

注意，对于其他类型的拓扑，应该设计另一个专门的拓扑感知门来提高性能。通过在特定的树状拓扑上演示这种拓扑感知门实例，我们提倡一种协同设计方法。在DDL-Roofline模型的指导下，可以很容易地设计出高吞吐量的门，并更好地理解其性能模式。

## 5 Evaluation
### 5.1 实验设置

我们在两个具有代表性的集群上评估了fastermoe。
+ ***johnny***是一个集群，在2个工作节点上有16个gpu。每个worker节点配置8块NVIDIA Tesla的pci - PCIe gpu，通过PCIe交换机连接到2个CPU插槽。尽管配备了Infiniband EDR，但由于板上缺乏×16 PCIE插槽，带宽降至50GB/s。Johnny群集代表了在深度学习训练中广泛使用的一类通用硬件。
+ ***trevor***是一台超级计算机的一个分区。每个节点上的NVIDIA V100- SXM2 gpu通过NVLink相互连接形成一个异构环，其中一半的边通过两条链路的键合具有双倍带宽。通信使用100Gb/s的Infiniband EDR。我们认为trevor是超级计算机的代表，用于深度学习和其他传统的HPC任务。在Trevor上分配了16个节点共64个GPU。

## 7 Conclusion

我们提出fastermoe，以解决在分布式训练MoE模型的挑战与性能模型和几个优化。性能由一个精确的通信和计算预测器和一个新的DDL-Roofline来建模，该DDL-Roofline显示了给定平台上特定训练任务的理论上限。在性能模型的指导下，我们提出了一种动态跟踪方法，可以减少负载不平衡带来的开销。同步操作符在工作组之间被分割成更小的任务，并被巧妙地调度为并发执行，最大限度地减少通信开销。我们还设计了一种**专家选择的方法**来避免网络中的拥塞，实现更高的吞吐量和有希望的收敛速度。fastermoe使大型动态MoE模型的训练效率提高了17.87。

# 视频

预训练模型近年深度学习领域最流行的模型 

![[Pasted image 20220819003638.png]]

主要结构是大规模的 Transformer 模型 

![[Pasted image 20220819003740.png]]

+ 每个输入需要巨大的计算
+ 能力出众


![[Pasted image 20220819003905.png]]

+ GShard 是 BERT 的 1800 倍大，但是性能显著提升。
+ 它只有1.5倍深，使用了MoE 结构，为每个 MLP(多层感知机) 模块部署了 2048 个专家
导致模型规模极大扩大

## MoE 结构（一种新的增大模型的结构）

![[Pasted image 20220819004120.png]]

+ Small model：能力较差
+ Dense large models：计算压力大

**MoE**：
+ 多个专家（small model）
+ 门网络，一个样本仅触发若干个专家。

+ 模型规模增大，能力更强
+ 计算压力小

## 专家并行

GShard 提出了专家并行

![[Pasted image 20220819004528.png]]

+ 专家和数据分布到若干个worker上

训练MoE层的时候，首先使用一个 `all-to-all` 操作把每一个输入发送到他们想到的worker上面去
![[Pasted image 20220819004659.png]]
专家对输入进行计算
![[Pasted image 20220819004712.png]]
再进行 `all-to-all` 操作，把输出分配到原来的位置。重新生成序列

## 专家并行的挑战

1. Stragglers due to load imbalance(负载不均衡)
2. 粗粒度的通信和计算操作带来的低效率问题 
3. 网络拥塞问题

对应的解决方法 
1. 影子专家 
2. 细粒度方案
3. Topology-aware gate 

提出了 DDL-Roofline

## 第一个挑战：Imbalanced Assignment

### 现象
1. 专家的选择分布可能存在严重不平衡![[Pasted image 20220819005120.png]]
2. 这个分布随着训练发生变化
![[Pasted image 20220819005226.png]]

### 例子 

![[Pasted image 20220819005345.png]]
1. 专家 1 非常受欢迎
2. worker 1 变成了 straggler

### 解决方法：影子专家
![[Pasted image 20220819005440.png]]

把专家 1 的参数进行广播，这样整体会更均衡

![[Pasted image 20220819005512.png]]

> 这里是设置了一个 **Performance predictor**，用来选择影子专家 

## 第二个挑战 粗粒度带来的低效

![[ezgif.com-gif-maker (2).gif]] 

+ MoE 层的每次计算，都包含两个 `all-to-all`
+ 做通信操作时，计算硬件在空闲
### 解决方法：pair-wise exchange Alg for all-to-all

把计算和通信划分为更细粒度操作

+ 在 $step_i$时
	+ $W_j$ 向 $W_{(j-i) \bmod n}$发送数据
   + 从$W_{(j+i) \bmod n}$接收数据
![[ezgif.com-gif-maker (3).gif]]

![[Pasted image 20220819010123.png]]
![[Pasted image 20220819010130.png]]
![[Pasted image 20220819010305.png]]
![[Pasted image 20220819010323.png]]
![[Pasted image 20220819010330.png]]
![[Pasted image 20220819010336.png]]

这样就完成了 `all-to-all` 操作 

### Task split-up

![[Pasted image 20220819010607.png]]

![[Pasted image 20220819010615.png]]
![[Pasted image 20220819010622.png]]
![[Pasted image 20220819010629.png]]

![[Pasted image 20220819010712.png#center|步骤之间的依赖关系]]
**最简单的方案**：
![[Pasted image 20220819010756.png]]
**比较好的**
![[Pasted image 20220819010827.png]]
**为了最大化效率**
1. 使用一组worker 
2. 通过**启发式分组**，最小化第一个S和最后一个R 

## 第三个挑战：跨节点网络的拥塞 

![[Pasted image 20220819011126.png]]
+ Node
	+ worker（GPU）
+ Node 之间通过网络连接，慢

**如果不对专家选择进行约束，那么慢速上层网络拥塞可能会比较严重**

### 解决方案 ：使用一个拓扑相关的门网络
![[Pasted image 20220819011419.png]]
+ 限制穿过上层网络的输入的数量 
+ 把多余的token在本地节点的专家中选一个 
+ **这个设计知识一个思路，不同特殊情况需要设置特殊的门网络，来进行效率提升**

## DDL-Roofline 
![[Pasted image 20220819011647.png]]
+ X：Rcc
+ Y：$\hat{P}$，每个加速器的平均吞吐量
![[Pasted image 20220819011738.png]]
+ 理想：计算和通信完美重叠
+ 半理想：不支持计算和通信重叠

### 若干个例子
#### 1. 数据并行
![[Pasted image 20220819011929.png]]
**缺陷**数据并行在MoE层有过多通信开销
**优化**可以通过overlapping越过半理想线
#### 2. 专家并行 

![[Pasted image 20220819012439.png]]

**缺陷：** 有更小的通信开销，但是负载不均衡
**优化**： 
+ 影子专家：减少不均衡
+ Smart-scheduling：overlapping
+ Topology-aware gate：减少通信量

## 实现 

+ 基于FaseMoE
+ 使用 Megatron-LM 作为 transformer 框架

## Baseline System for Comparison

![[Pasted image 20220819012545.png]]

![[Pasted image 20220819012639.png]]

### 评估设置 
![[Pasted image 20220819012705.png]]
### 结果 
![[Pasted image 20220819012728.png]]
![[Pasted image 20220819012742.png]]
> 对比收敛速度 ，因为修改了模型本身的行为 

## 总结  FasterMoE in a Nutshell

![[Pasted image 20220819012856.png]]
![[Pasted image 20220819012904.png]]
![[Pasted image 20220819012913.png]]

![[Pasted image 20220819012924.png]]
> 使用 DDL-Roofline 模型来刻画他们的性能